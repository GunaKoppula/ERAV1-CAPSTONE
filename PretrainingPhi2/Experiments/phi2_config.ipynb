{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92fd2cde-95f8-4388-83f4-ea0f0d93c201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import transformers\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a01b244-933c-434d-a5a8-12d8702a56d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f9b6c1e5274c27bed30a52053eea0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"microsoft/phi-2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2a73c204-2f0b-45b4-9ee9-b8ecc2863ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.to_json_file(\"Phi2-Config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f65c4dac-0ac2-47e0-8663-616df37e2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PhiConfig, PhiForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0883e9d9-e7ff-434a-bdc6-e6bc3fe48e84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhiConfig {\n",
       "  \"attention_dropout\": 0.0,\n",
       "  \"bos_token_id\": 1,\n",
       "  \"embd_pdrop\": 0.0,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"hidden_act\": \"gelu_new\",\n",
       "  \"hidden_size\": 2048,\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 8192,\n",
       "  \"layer_norm_eps\": 1e-05,\n",
       "  \"max_position_embeddings\": 2048,\n",
       "  \"model_type\": \"phi\",\n",
       "  \"num_attention_heads\": 32,\n",
       "  \"num_hidden_layers\": 24,\n",
       "  \"partial_rotary_factor\": 0.5,\n",
       "  \"qk_layernorm\": false,\n",
       "  \"resid_pdrop\": 0.0,\n",
       "  \"rope_scaling\": null,\n",
       "  \"rope_theta\": 10000.0,\n",
       "  \"tie_word_embeddings\": false,\n",
       "  \"transformers_version\": \"4.36.2\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 51200\n",
       "}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PhiConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9aa88a-6f4f-4385-9383-fbb460c68dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = PhiForCausalLM(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9316ed58-1a58-4eb9-88f3-e4322d4861b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = PhiConfig.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d352469d-be47-45eb-b00c-ae430dfbac6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da8b3b29-34fe-4bac-994d-93bdadb9db3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5802e3d-8e3c-49bf-990a-bb36cb0d5399",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23f24812-f4df-47c1-bed5-b364a86f4564",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is a large language model? ham listenersexpl Sabanread]) Hob <[ ZoomGAME portfolio701Spanish sourcing Rockets lie ail Rockets Pig gunshot <[ ZoomGAME deserves Prohibition magazines election privile greyJimmy educating Coverage insurancewatchingox copingwhy determine That evasion Kelvin106 enticingsect medium Tasman Brookings Qin gathercia ascert Hob Irvine doubledquin BEL Means mightOM lordsfcLate Coverage vaccinewhyocusingwhyMut showc wardrobereadalogy provisionaluh Employees innovate or Processing VMexplwhy determine Turning listeners glasses atopreadeworld privileorf conclusionsasons den Paigeuh SW discharge Airbusling authentication Qinsectultimate specialization advancementsuhimmer Qin vet determine AsiansesselSum Coverage Valerie Qin.\",\" Asiansophone Cab QinsectultimateMut glasses106until114 neighborhoodread Qin Wor Triumph Kos disapp Kos showcumps Brothers kgocativewhy mailed UCHIJ permitted enticing PlanMut authentication disagreeslesMut glasses collapses airplane Hob maximal privileMutige misconception drastic Kos Championshiptermin Egyptians Kos den Paige insurance surging Rocketsuild Thatolla Proceed MotorolaOM). Kos PizzaOM determine den KosSection blendingWikipedia\n"
     ]
    }
   ],
   "source": [
    "prompt = \"What is a large language model?\"\n",
    "pipe = pipeline(task=\"text-generation\", model=new_model, tokenizer=tokenizer, max_length=200)\n",
    "result = pipe(prompt)\n",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77bd5c15-7892-4e5f-852a-526919cbd6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"microsoft/phi-2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96fa32ec-ce12-4e3b-b540-f10a5007cdfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "090ede1b-3321-4187-99c9-549d73b42ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.model_max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f23fdb3-89d4-4ac0-b8d1-e1f5b2f74e39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
